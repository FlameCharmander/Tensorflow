{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./model/save/implementation_3/\"\n",
    "model_file = save_path+\"model-9500.meta\"\n",
    "data_path = \"data/sentiment_analysis/\"\n",
    "positive_file = data_path + \"sst_pos_sentences_id.txt\"\n",
    "negative_file = data_path + \"sst_neg_sentences_id.txt\"\n",
    "vocab_file = data_path + \"sst_vocab.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emb_data(emb_dict_file):\n",
    "    word_dict = {}\n",
    "    word_list = []\n",
    "    item = 0\n",
    "    with open(emb_dict_file, 'r', encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            word = line.strip()\n",
    "            word_dict[word] = item\n",
    "            item += 1\n",
    "            word_list.append(word)\n",
    "    length = len(word_dict)\n",
    "    print(\"Load embedding success! Num: %d\" % length)\n",
    "    return word_dict, length, word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load embedding success! Num: 4734\n",
      "INFO:tensorflow:Restoring parameters from ./model/save/implementation_3/model-9500\n",
      "a mess far from start to tedious dialogue very scary -- succumbs to cliches very\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    vocab_dict, vocab_size, word_list = load_emb_data(vocab_file)\n",
    "    with tf.Session() as sess:\n",
    "        #restore first\n",
    "        saver = tf.train.import_meta_graph(model_file)\n",
    "        saver.restore(sess,tf.train.latest_checkpoint(save_path))\n",
    "        graph = tf.get_default_graph()\n",
    "        initial_state_op = graph.get_tensor_by_name(\"inference/initial_state:0\")\n",
    "        state_op = graph.get_tensor_by_name(\"inference/states:0\")\n",
    "        token_placeholder = graph.get_tensor_by_name(\"placeholder/token:0\")\n",
    "        next_state_placeholder = graph.get_tensor_by_name(\"placeholder/next_state:0\")\n",
    "        prediction_op = graph.get_tensor_by_name(\"inference/prediction:0\")\n",
    "        initial_state = sess.run(initial_state_op)\n",
    "        #next_state = np.zeros(shape=[1, 64])\n",
    "        next_state = initial_state\n",
    "        token = [vocab_dict['<GO>']]\n",
    "        token_list = list()\n",
    "        for i in range(100):\n",
    "            token, next_state = sess.run([prediction_op,state_op], feed_dict={token_placeholder:token, next_state_placeholder:next_state})\n",
    "            if (token == [vocab_dict['<EOS>']]):\n",
    "                pass\n",
    "            else:\n",
    "                token_list.extend(token)\n",
    "        print(\" \".join([word_list[x] for x in token_list if x != vocab_dict['<PAD>']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
